# 闻声知乐

## 1. 项目架构
### 1.1 数据与模型训练
使用了CASIA情感语音数据集，pytorch搭建深度学习模型进行训练。
- extract_features.py：封装了提取音频特征的方法。
- transforms.py：提取出的特征输入模型前进行的变换。
- dataset.py：构建数据集的方法和类。
- augmentation.py：对数据增强的一些方法。
- models.ipynb：训练、保存模型。模型存放在pickles目录下。

### 1.2 系统
本系统采用前后端分离SPA（单页面应用）模式，位于app文件夹中：
- 前端：使用vue.js，实现了接受音频上传的组件，并将音频流向后端发送。
- 后端：使用python+flask，部署模型，接受来自前端的音频流进行预测。

前后端分别位于app/frontend和app/backend中。

后端主要代码实现在app/app.py中。

## 2. 课程知识的体现
- 面向对象设计：对于数据集类、变换类的封装。
- 并行与并发：读取数据集时，使用多线程并发，cpu负载达到100%，大约节省100s时间。
- etc……

## ３. Some Details
- tutorials文件夹：里面记录了我的一些学习过程，还有相关资料。
- 略有遗憾的地方：前端经验不够丰富，没有想到颜值比较高的方法来渲染预测结果。。。
- **原创性声明：除了某些前端组件，其余均为自己实现。**
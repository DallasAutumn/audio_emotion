{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T12:26:27.702221Z",
     "start_time": "2019-12-30T12:21:47.938803Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from os.path import join as path_join\n",
    "from time import time\n",
    "\n",
    "from joblib import Parallel\n",
    "from torchvision.transforms import Compose, Resize\n",
    "\n",
    "from config import ROOT_DIR\n",
    "from dataset import MfccDataset\n",
    "from transforms import *\n",
    "\n",
    "seq_len = 224\n",
    "\n",
    "trans = Compose([ToTensor(),\n",
    "                 PaddingSame2d(seq_len=seq_len, value=0)])\n",
    "\n",
    "start = time()\n",
    "\n",
    "train_set = MfccDataset(\n",
    "    root=path_join(ROOT_DIR, \"相同文本300\"), train=True, transform=trans, n_jobs=-1)\n",
    "\n",
    "val_set = MfccDataset(\n",
    "    root=path_join(ROOT_DIR, \"不同文本100\"), transform=trans, n_jobs=-1)\n",
    "\n",
    "test_set = MfccDataset(\n",
    "    root=path_join(ROOT_DIR, \"相同文本300\"), train=False, transform=trans, n_jobs=-1)\n",
    "\n",
    "print('total time:', time()-start)\n",
    "\n",
    "print(train_set)\n",
    "print(val_set)\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**多线程读取大约能节省100s**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T12:27:31.634961Z",
     "start_time": "2019-12-30T12:26:27.703826Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(17377191)\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    \"\"\"Note that batch_size is the first dimension\"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)  # [batch, seq_len*input_size]\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=13, stride=13),\n",
    "            #             nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            #             nn.Dropout(0.1),\n",
    "            Flatten(),\n",
    "            nn.Linear(136, 6),\n",
    "\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(dim=1)\n",
    "        x = self.cnn(x)\n",
    "        return x\n",
    "\n",
    "# the training loop\n",
    "\n",
    "\n",
    "def main(model):\n",
    "    # hyper params\n",
    "    T = 20\n",
    "    learning_rate = 5e-5\n",
    "    batch_size = 32\n",
    "    epochs = 100\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Now using {device}\")\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_set+val_set, num_workers=4,\n",
    "                              shuffle=True, batch_size=batch_size)\n",
    "    val_loader = DataLoader(dataset=val_set, num_workers=4,\n",
    "                            shuffle=True, batch_size=batch_size)\n",
    "    test_loader = DataLoader(dataset=test_set, num_workers=4,\n",
    "                             shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # training\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        print(f\"epoch {epoch}\")\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, (x, y) in enumerate(train_loader, start=0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = Variable(x).type(torch.cuda.FloatTensor)\n",
    "            labels = Variable(y).type(torch.cuda.LongTensor)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % T == 0:    # print every T mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / T))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                test_x = x.type(torch.cuda.FloatTensor)\n",
    "                labels = y.type(torch.cuda.LongTensor)\n",
    "                outputs = model(test_x)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        acc = correct / total\n",
    "        print('Accuracy : %d %%' % (100 * acc))\n",
    "#         plt.plot(epoch, acc)\n",
    "        print()\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cnn = CNN()\n",
    "    main(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T12:27:31.644345Z",
     "start_time": "2019-12-30T12:27:31.637237Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = \"./pickles/cnn.pkl\"\n",
    "torch.save(cnn.state_dict(), model_path)\n",
    "print('Saved at', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T12:28:49.477226Z",
     "start_time": "2019-12-30T12:28:49.472035Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn.state_dict().get('cnn.0.weight').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T12:38:43.444260Z",
     "start_time": "2019-12-30T12:38:43.414247Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=13, stride=13),\n",
    "            #             nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            #             nn.Dropout(0.1),\n",
    "            Flatten(),\n",
    "            nn.Linear(136, 6),\n",
    "\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(dim=1)\n",
    "#         x = self.cnn(x)\n",
    "        for layer in self.cnn:\n",
    "            x = layer(x)\n",
    "            print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "test_cnn = CNN()\n",
    "test_cnn(torch.Tensor(13, 224).unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T12:35:10.770917Z",
     "start_time": "2019-12-30T12:35:10.658053Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = iter(DataLoader(dataset=train_set+val_set, num_workers=4,\n",
    "                               shuffle=True, batch_size=1))\n",
    "next(train_loader)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T12:39:36.976234Z",
     "start_time": "2019-12-30T12:39:36.970136Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.Tensor(13, 224).unsqueeze(dim=0).shape"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
